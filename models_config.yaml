models:
  # OpenAI Models
  gpt-4:
    provider: "openai"
    model_name: "gpt-4"
    temperature: 0.1
    max_tokens: 1000
    description: "OpenAI GPT-4 - Most capable model"

  gpt-4-turbo:
    provider: "openai"
    model_name: "gpt-4-turbo"
    temperature: 0.1
    max_tokens: 1000
    description: "OpenAI GPT-4 Turbo - Faster and cheaper"

  gpt-3.5-turbo:
    provider: "openai"
    model_name: "gpt-3.5-turbo"
    temperature: 0.1
    max_tokens: 1000
    description: "OpenAI GPT-3.5 Turbo - Fast and cost-effective"

  # Anthropic Models
  claude-3-5-sonnet:
    provider: "anthropic"
    model_name: "claude-3-5-sonnet-20241022"
    temperature: 0.1
    max_tokens: 1000
    description: "Anthropic Claude 3.5 Sonnet - Latest Claude model"

  claude-3-haiku:
    provider: "anthropic"
    model_name: "claude-3-haiku-20240307"
    temperature: 0.1
    max_tokens: 1000
    description: "Anthropic Claude 3 Haiku - Fast and efficient"

  # Google Models
  gemini-pro:
    provider: "google"
    model_name: "gemini-pro"
    temperature: 0.1
    max_tokens: 1000
    description: "Google Gemini Pro - Multimodal capabilities"
    env_var: "GOOGLE_API_KEY"

  # Hugging Face Models (via LangChain)
  llama2-7b:
    provider: "huggingface"
    model_name: "meta-llama/Llama-2-7b-chat-hf"
    temperature: 0.1
    max_tokens: 1000
    description: "Meta Llama 2 7B - Open source model"
    env_var: "HUGGINGFACE_API_TOKEN"

    # Local Ollama Models
  mistral:
    provider: "ollama"
    model_name: "mistral:latest"
    temperature: 0.1
    max_tokens: 1000
    description: "Mistral 7B - High-quality local model (4.1GB)"

# Provider configurations
providers:
  openai:
    env_var: "OPENAI_API_KEY"
    langchain_class: "ChatOpenAI"

  anthropic:
    env_var: "ANTHROPIC_API_KEY"
    langchain_class: "ChatAnthropic"

  google:
    env_var: "GOOGLE_API_KEY"
    langchain_class: "ChatGoogleGenerativeAI"

  huggingface:
    env_var: "HUGGINGFACE_API_TOKEN"
    langchain_class: "HuggingFaceHub"

  ollama:
    base_url: "http://localhost:11434"
    langchain_class: "ChatOllama"

# Default settings
defaults:
  temperature: 0.1
  max_tokens: 1000
  timeout: 30
